{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "wrapper = textwrap.TextWrapper(width=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'mistralai/Mixtral-8x7B-Instruct-v0.1'\n",
    "model_name = 'mistralai/Mistral-7B-Instruct-v0.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core.llms import ChatMessage, MessageRole\n",
    "# from llama_index.core import ChatPromptTemplate\n",
    "\n",
    "# # Text QA Prompt\n",
    "# chat_text_qa_msgs = [\n",
    "#     ChatMessage(\n",
    "#         role=MessageRole.SYSTEM,\n",
    "#         content=(\n",
    "#             \"Always answer the question, even if the context isn't helpful.\"\n",
    "#         ),\n",
    "#     ),\n",
    "#     ChatMessage(\n",
    "#         role=MessageRole.USER,\n",
    "#         content=(\n",
    "#             \"Context information is below.\\n\"\n",
    "#             \"---------------------\\n\"\n",
    "#             \"{context_str}\\n\"\n",
    "#             \"---------------------\\n\"\n",
    "#             \"Given the context information and not prior knowledge, \"\n",
    "#             \"answer the question: {query_str}\\n\"\n",
    "#         ),\n",
    "#     ),\n",
    "# ]\n",
    "# text_qa_template = ChatPromptTemplate(chat_text_qa_msgs)\n",
    "\n",
    "# # Refine Prompt\n",
    "# chat_refine_msgs = [\n",
    "#     ChatMessage(\n",
    "#         role=MessageRole.SYSTEM,\n",
    "#         content=(\n",
    "#             \"Always answer the question, even if the context isn't helpful.\"\n",
    "#         ),\n",
    "#     ),\n",
    "#     ChatMessage(\n",
    "#         role=MessageRole.USER,\n",
    "#         content=(\n",
    "#             \"We have the opportunity to refine the original answer \"\n",
    "#             \"(only if needed) with some more context below.\\n\"\n",
    "#             \"------------\\n\"\n",
    "#             \"{context_msg}\\n\"\n",
    "#             \"------------\\n\"\n",
    "#             \"Given the new context, refine the original answer to better \"\n",
    "#             \"answer the question: {query_str}. \"\n",
    "#             \"If the context isn't useful, output the original answer again.\\n\"\n",
    "#             \"Original Answer: {existing_answer}\"\n",
    "#         ),\n",
    "#     ),\n",
    "# ]\n",
    "# refine_template = ChatPromptTemplate(chat_refine_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfdb66920f674789bf9f40c6c07f914c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "# from llama_index.prompts.prompts import SimpleInputPrompt\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "# Context Window specifies how many tokens to use as context for the LLM\n",
    "context_window = 2048\n",
    "# Max New Tokens specifies how many new tokens to generate for the LLM\n",
    "max_new_tokens = 256\n",
    "# Device specifies which device to use for the LLM\n",
    "device = \"cuda\"\n",
    "\n",
    "# This is the prompt that will be used to instruct the model behavior\n",
    "system_prompt = \"\"\"\n",
    "I. Introduction:\n",
    "    Identify yourself: \"I am an AI chatbot designed to answer your questions about E2E Networks.\"\n",
    "    Explain your function: \"I can answer your questions based on the information provided to me. If the information isn't enough, I'll guide you to the E2E Networks Support team for further assistance.\"\n",
    "\n",
    "II. Input:\n",
    "    Context: \"You will be provided with a context (information) related to E2E Networks.\"\n",
    "    Question: \"You will be asked a question relevant to the provided context.\"\n",
    "\n",
    "III. Output:\n",
    "    Answer: \"I will answer your question directly based on the information in the context.\"\n",
    "    External resources: \"If the context is insufficient, I will not answer based on general knowledge. Instead, I will direct you to the E2E Networks Support team and provide any relevant links found in the context, such as the official website: E2E Networks Official Website: https://www.e2enetworks.com/.\"\n",
    "    First-person perspective: \"I will always use the first-person perspective (e.g., I, us, our) to answer your questions, making the interaction feel natural and human-like.\"\n",
    "\n",
    "IV. Limitations:\n",
    "    Knowledge limitations: \"My knowledge is confined to the information provided and should not be considered comprehensive.\"\n",
    "    Independent reasoning: \"I cannot use independent reasoning or personal opinions in my responses.\"\n",
    "\"\"\"\n",
    "\n",
    "# This will wrap the default prompts that are internal to llama-index\n",
    "query_wrapper_prompt = PromptTemplate(\"<|USER|>{query_str}<|ASSISTANT|>\")\n",
    "\n",
    "# Create the LLM using the HuggingFaceLLM class\n",
    "llm = HuggingFaceLLM(\n",
    "    context_window=context_window,\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    system_prompt=system_prompt,\n",
    "    query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name=model_name,\n",
    "    model_name=model_name,\n",
    "    device_map=device,\n",
    "    # uncomment this if using CUDA to reduce memory usage\n",
    "    # model_kwargs={\n",
    "    #     # \"torch_dtype\": torch.float16\n",
    "    #     'quantization_config':quantization_config\n",
    "    # }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_name = \"BAAI/bge-large-en-v1.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceBgeEmbeddings\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "\n",
    "# Create the embedding model using the HuggingFaceBgeEmbeddings class\n",
    "embed_model = LangchainEmbedding(\n",
    "  HuggingFaceBgeEmbeddings(model_name=embedding_model_name)\n",
    ")\n",
    "\n",
    "# Get the embedding dimension of the model by doing a forward pass with a dummy input\n",
    "embed_dim = len(embed_model.get_text_embedding(\"Hello world\")) # 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = \"postgresql://postgres:test123@localhost:5432\"\n",
    "db_name = \"chatbotdb\"\n",
    "table_name = 'companyDocEmbeddings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "Settings.chunk_size = 2048\n",
    "Settings.chunk_overlap = 256\n",
    "\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.transformations = [SentenceSplitter(chunk_size=1024)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import make_url\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "# Creates a URL object from the connection string\n",
    "url = make_url(connection_string)\n",
    "\n",
    "# Create the vector store\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=db_name,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port,\n",
    "    user=url.username,\n",
    "    table_name=table_name,\n",
    "    embed_dim=embed_dim,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# Load the index from the vector store of the database\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.retriever_query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.indices.vector_store.retrievers.retriever import VectorIndexRetriever\n",
    "from llama_index.core import get_response_synthesizer\n",
    "\n",
    "# Create the retriever that manages the index and the number of results to return\n",
    "retriever = VectorIndexRetriever(\n",
    "      index=index,\n",
    "      similarity_top_k=5,\n",
    ")\n",
    "\n",
    "# Create the response synthesizer that will be used to synthesize the response\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "      response_mode='accumulate',\n",
    ")\n",
    "\n",
    "# Create the query engine that will be used to query the retriever and synthesize the response\n",
    "query_engine = RetrieverQueryEngine(\n",
    "      retriever=retriever,\n",
    "      response_synthesizer=response_synthesizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query('Do you know about e2e networks? What is e2e networks? And what all services do they provide?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: I am an AI chatbot designed to answer your questions about E2E Networks. Based on the context provided, E2E Networks Limited is\n",
      "India's fastest growing accelerated cloud computing player. The context does not explicitly mention the services they provide, but it can be\n",
      "inferred that they specialize in cloud computing. For more detailed information about their services, I would recommend visiting their\n",
      "official website or contacting their support team. Here's the link to their website: https://www.e2enetworks.com/ ---------------------\n",
      "Response 2: I am an AI chatbot designed to answer your questions about E2E Networks. Based on the context provided, E2E Networks is a\n",
      "company that offers various cloud services. Specifically, they provide Webuzo Linux Cloud plans, which include full root access, licensing\n",
      "at no extra cost, and one-click install for 450+ apps using Softaculous. The plans come with different vCPU, CPU frequency, dedicated RAM,\n",
      "disk space, and prices. For more details, you can visit their official website: https://www.e2enetworks.com/ or try their free trials by\n",
      "following the links provided in the context. --------------------- Response 3: I am an AI chatbot designed to answer your questions about\n",
      "E2E Networks based on the provided context. According to the context, E2E Networks is a company that offers various cloud computing\n",
      "services. Specifically, they provide High Memory Cloud instances with different configurations, each having varying vCPUs, CPU frequencies,\n",
      "dedicated RAM, and disk space. These instances are suitable for memory-intensive workloads and computing. For more information, you can\n",
      "visit their official website: https://www.e2enetworks.com/ or contact their sales representatives at +91-11-4084-4965 or\n",
      "sales@e2enetworks.com. --------------------- Response 4: I am an AI chatbot designed to answer your questions about E2E Networks. E2E\n",
      "Networks is a cloud service provider that offers various services including E2E Object Storage (EOS), E2E Volumes, and E2E CDP Backup. E2E\n",
      "Object Storage is an SSD-based S3-compatible object storage service designed for demanding workloads like machine learning and deep\n",
      "learning. E2E Volumes provide block-level storage volumes to use with their compute nodes. And E2E CDP Backup is a backup service that backs\n",
      "up your VM or cloud instance data continually, incrementally, and automatically on E2E Cloud. For more information, you can visit their\n",
      "official website: https://www.e2enetworks.com/ or contact their sales representatives at +91-11-4084-4965 or sales@e2enetworks.com.\n",
      "--------------------- Response 5: I am an AI chatbot designed to answer your questions about E2E Networks. Based on the context provided,\n",
      "E2E Networks is a cloud service provider that offers Windows Server workloads on their cloud platform. They provide pre-configured security\n",
      "settings, networking, and excellent price-performance ratio. The services they offer include Windows Cloud with various plans, each having\n",
      "different physical cores, CPU frequencies, dedicated RAM, disk space, and prices. The plans range from CW.20GB to CW.540GB, with varying\n",
      "numbers of CPU cores and prices. For more information, you can visit their official website or request a free trial.\n"
     ]
    }
   ],
   "source": [
    "print(wrapper.fill(response.response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query('What is the price of 8xH100?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1: I'm unable to directly answer that question based on the context provided. The context only mentions the prices for 2xA100,\n",
      "4xA100, and no information about the price for 8xH100 is given. I recommend checking the official E2E Networks website or contacting their\n",
      "sales team for the most accurate and up-to-date information. Here's the link to their website: https://www.e2enetworks.com/ and their\n",
      "contact information: [+91-11-4084-4965](http://callto:+91-11-4084-4965) and [sales@e2enetworks.com](mailto:sales@e2enetworks.com).\n",
      "--------------------- Response 2: Based on the context provided, I cannot directly answer your question as the price for an 8xH100\n",
      "configuration is not listed. However, I can guide you to the E2E Networks Support team for further assistance. They can be reached at\n",
      "[+91-11-4084-4965](http://callto:+91-11-4084-4965) or [sales@e2enetworks.com](mailto:sales@e2enetworks.com). Additionally, you may find more\n",
      "information on their official website: https://www.e2enetworks.com/ --------------------- Response 3: I cannot directly answer that question\n",
      "based on the provided context. However, I can see that the context includes information about various plans, including the M3.48GB plan\n",
      "which has 8 vCPUs. The price for the M3.48GB plan is ₹7,446 per month. If you meant a different product or configuration, please provide\n",
      "more context or clarify your question. If you need further assistance, please contact the E2E Networks Support team at +91-11-4084-4965 or\n",
      "sales@e2enetworks.com. --------------------- Response 4: The price for 8xH100 is Rs. 7,48,80,000. --------------------- Response 5: I cannot\n",
      "directly answer that question based on the provided context. The context only lists the prices for various configurations of the NVIDIA L4\n",
      "GPU. The H100 GPU is not mentioned in the context. However, I can guide you to the E2E Networks Support team for further assistance. They\n",
      "can provide you with the most accurate and up-to-date pricing information. Here's the link to their contact information:\n",
      "[+91-11-4084-4965](http://callto:+91-11-4084-4965) or [sales@e2enetworks.com](mailto:sales@e2enetworks.com).\n"
     ]
    }
   ],
   "source": [
    "print(wrapper.fill(response.response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='87c8faf8-d9fd-43c5-a8b1-a4ec9aae3560', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='https://www.e2enetworks.com/pricing', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='09c838495f7a657ec983a961e9cf7dbd397e95c46a386923d20904bb330d32f0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='f383a04e-6f91-448d-967e-e195b6e474b7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3be95528f2a53b2c974e25fc0be74761ee77aac3ca11f13e6cfadaba6e514ded'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='2607b591-1f01-4838-97c8-36065308ad39', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='6cbdc136a4aa54f0ece0c44707b27f91b72666813451bbe5db26f0b585ac3533')}, text='04,654\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n2xA100\\n\\n2 x 80 GB\\n\\n32 vCPUs\\n\\n230 GB\\n\\n3000 GB SSD\\n\\nâ\\x82¹463/hr\\n\\nâ\\x82¹75000\\n\\nâ\\x82¹2,07,984\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n4xA100\\n\\n4 x 80 GB\\n\\n64 vCPUs\\n\\n460 GB\\n\\n6000 GB SSD\\n\\nâ\\x82¹924/hr\\n\\nâ\\x82¹150000\\n\\nâ\\x82¹4,14,645\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n[Read More](/products/nvidia-a100-80-gb)[Request a Free\\nTrial](https://forms.zohopublic.com/e2enetworks/form/Requestfortrial/formperma/SdPEABJpefRANPQ0WiAms_0DaAOfgJ0omyfvxdCx7tM)\\n\\nOur sales representatives are available at\\n[+91-11-4084-4965](http://callto:+91-11-4084-4965) and\\n[sales@e2enetworks.com](mailto:sales@e2enetworks.com)  \\n\\n* Price is exclusive of 18% GST Rate\\n\\n** Monthly Prices shown are calculated using an assumed usage of 730 hr/month;\\nactual monthly costs may vary based on the number of days in a month.\\n\\n## L40S\\n\\nLaunch the powerful universal GPU delivering breakthrough multi-workload\\nacceleration for large language model (LLM) inference and training, graphics,\\nand video applications, with E2E Cloud.', start_char_idx=6995, end_char_idx=8111, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6027732907899365),\n",
       " NodeWithScore(node=TextNode(id_='2607b591-1f01-4838-97c8-36065308ad39', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='https://www.e2enetworks.com/pricing', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='09c838495f7a657ec983a961e9cf7dbd397e95c46a386923d20904bb330d32f0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='87c8faf8-d9fd-43c5-a8b1-a4ec9aae3560', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='ff8f5ea858c16bdde7633479fdd8e4f2f67988be1e73a469b8d1045536f8a612'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='e0e73c53-2e62-47f9-8e75-18b2d535df3c', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='44fcd1ac144bdc138201eca7943b130cb91dc8032aeb8fd95133fff5ce9df5ec')}, text='zohopublic.com/e2enetworks/form/Requestfortrial/formperma/SdPEABJpefRANPQ0WiAms_0DaAOfgJ0omyfvxdCx7tM)\\n\\nOur sales representatives are available at\\n[+91-11-4084-4965](http://callto:+91-11-4084-4965) and\\n[sales@e2enetworks.com](mailto:sales@e2enetworks.com)  \\n\\n* Price is exclusive of 18% GST Rate\\n\\n** Monthly Prices shown are calculated using an assumed usage of 730 hr/month;\\nactual monthly costs may vary based on the number of days in a month.\\n\\n## L40S\\n\\nLaunch the powerful universal GPU delivering breakthrough multi-workload\\nacceleration for large language model (LLM) inference and training, graphics,\\nand video applications, with E2E Cloud.  \\n\\nLinux L40S Windows L40S\\n\\nLinux L40S\\n\\nPlan\\n\\nvCPUs\\n\\nDedicated RAM\\n\\n **Disk Space**\\n\\n **Hourly Billing**  \\n\\n **Weekly Billing**\\n\\nMonthly Billing\\n\\n3 months Billing\\n\\n6 months Billing\\n\\nYearly  \\nBilling  \\n\\n  \\n\\n36 months Billing\\n\\nL40S\\n\\n25 vCPUs\\n\\n220 GB\\n\\n250 GB SSD\\n\\nâ\\x82¹200/hr\\n\\nâ\\x82¹28,000\\n\\nâ\\x82¹1,00,000  \\n\\nâ\\x82¹3,00,000\\n\\nâ\\x82¹6,00,000\\n\\n **â\\x82¹10,80,000**\\n\\nâ\\x82¹28,80,000\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n2xL40S\\n\\n50 vCPUs\\n\\n440 GB\\n\\n250 GB SSD\\n\\nâ\\x82¹400hr\\n\\nâ\\x82¹56,000\\n\\nâ\\x82¹2,00,000\\n\\nâ\\x82¹6,00,000\\n\\nâ\\x82¹12,00,000\\n\\n **â\\x82¹21,60,000**\\n\\nâ\\x82¹57,60,000\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n4xL40S\\n\\n100 vCPUs\\n\\n880 GB\\n\\n250 GB SSD\\n\\nâ\\x82¹800/hr\\n\\nâ\\x82¹1,12,000\\n\\nâ\\x82¹4,00,000\\n\\nâ\\x82¹12,00,000\\n\\nâ\\x82¹24,00,000\\n\\n **â\\x82¹43,20,000**\\n\\nâ\\x82¹11,520,000\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n[Read More](/products/l40s-cloud-gpu)[Request a Free\\nTrial](https://forms.zohopublic.com/e2enetworks/form/Requestfortrial/formperma/SdPEABJpefRANPQ0WiAms_0DaAOfgJ0omyfvxdCx7tM)\\n\\nWindows L40S\\n\\nPlan\\n\\nvCPUs\\n\\nDedicated RAM\\n\\n **Disk Space**\\n\\n **Hourly Billing**  \\n\\n **Weekly Billing**\\n\\nMonthly Billing\\n\\n3 months Billing\\n\\n6 months Billing\\n\\nYearly  \\nBilling  \\n\\n  \\n\\n36 months Billing\\n\\nL40S\\n\\n25 vCPUs\\n\\n220 GB\\n\\n250 GB SSD\\n\\nâ\\x82¹211/hr\\n\\nâ\\x82¹30,000\\n\\nâ\\x82¹1,08,023  \\n\\nâ\\x82¹3,24,069\\n\\nâ\\x82¹6,48,138\\n\\n **â\\x82¹11,76,276**\\n\\nâ\\x82¹31,68,828\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n2xL40S\\n\\n50 vCPUs\\n\\n440 GB\\n\\n250 GB SSD\\n\\nâ\\x82¹419/hr\\n\\nâ\\x82¹60,000\\n\\nâ\\x82¹2,13,843\\n\\nâ\\x82¹6,41,529\\n\\nâ\\x82¹1,283,058\\n\\n **â\\x82¹23,26,116**\\n\\nâ\\x82¹62,58,348\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n4xL40S\\n\\n100 vCPUs\\n\\n880 GB\\n\\n250 GB SSD\\n\\nâ\\x82¹836/hr\\n\\nâ\\x82¹1,20,000\\n\\nâ\\x82¹4,25,968\\n\\nâ\\x82¹12,77,904\\n\\nâ\\x82¹25,55,808\\n\\n **â\\x82¹46,31,616**\\n\\nâ\\x82¹12,454,848\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n[Read More](https://www.e2enetworks.com/product/nvidia-tesla-v100)[Request a\\nFree\\nTrial](https://forms.zohopublic.com/e2enetworks/form/Requestfortrial/formperma/SdPEABJpefRANPQ0WiAms_0DaAOfgJ0omyfvxdCx7tM)\\n\\nOur sales representatives are available at\\n[+91-11-4084-4965](http://callto:+91-11-4084-4965) and\\n[sales@e2enetworks.com](mailto:sales@e2enetworks.com)  \\n\\n* Price is exclusive of 18% GST Rate\\n\\n** Monthly Prices shown are calculated using an assumed usage of 730 hr/month;\\nactual monthly costs may vary based on the number of days in a month.', start_char_idx=7465, end_char_idx=10499, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5997169494966371),\n",
       " NodeWithScore(node=TextNode(id_='d8dc0588-1186-48de-94f1-ffa4fc36a83e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='https://www.e2enetworks.com/pricing', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='09c838495f7a657ec983a961e9cf7dbd397e95c46a386923d20904bb330d32f0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='533d2fbf-126b-4d5a-900c-e6b109126702', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='68f0451832aa9c0e91495a351b12f7b7737e16e36d0c4dc796552245602a3fc5'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='4b6c4604-2e72-4ef5-a2db-d2c188d2b647', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='1b9052d50be3350d94ca2e96224278139a7580b831f3a4602528e0038303d503')}, text='com](mailto:sales@e2enetworks.com)  \\n\\n* Price is exclusive of 18% GST Rate\\n\\n** Monthly Prices shown are calculated using an assumed usage of 730 hr/month;\\nactual monthly costs may vary based on the number of days in a month.\\n\\n## High Memory Cloud\\n\\nAccess in-memory data faster, nearly 100x faster compared to latest NVMe flash\\nstorage. Run memcached, redis or any other memory intensive workload on these\\ninstances.  \\n  \\nUse larger cache configurations to achieve lightening fast responses at a\\nlower latency.  \\n  \\nGenerously large number of vCPUs for high throughput on multi-threaded server\\nsoftwares and plenty of diskspace to enable full utilization of memory\\nintensive compute nodes.\\n\\nMemory Intensive Computing - M3 Series\\n\\nPlan\\n\\nvCPUs\\n\\nCPU Frequency\\n\\nDedicated RAM\\n\\nDisk Space\\n\\nPrice  \\n(Billed Hourly)\\n\\nPrice  \\n(Billed Monthly)\\n\\nM3.32GB\\n\\n4 vCPUs\\n\\nâ\\x89¥ 2.3 GHz\\n\\n32 GB\\n\\n100 GB SSD NVMe\\n\\nâ\\x82¹5.1/hr\\n\\nâ\\x82¹3,723/mo\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\nM3.48GB\\n\\n8 vCPUs\\n\\nâ\\x89¥ 2.3 GHz\\n\\n48 GB\\n\\n150 GB SSD NVMe\\n\\nâ\\x82¹10.2/hr\\n\\nâ\\x82¹7,446/mo\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\nM3.96GB\\n\\n12 vCPUs\\n\\nâ\\x89¥ 2.3 GHz\\n\\n96 GB\\n\\n200 GB SSD NVMe\\n\\nâ\\x82¹20.4/hr\\n\\nâ\\x82¹14,892/mo\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\nM3.128GB\\n\\n16 vCPUs\\n\\nâ\\x89¥ 2.3 GHz\\n\\n128 GB\\n\\n300 GB SSD NVMe\\n\\nâ\\x82¹30.6/hr\\n\\nâ\\x82¹22,338/mo\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\nM3.192GB\\n\\n24 vCPUs\\n\\nâ\\x89¥ 2.3 GHz\\n\\n192 GB\\n\\n450 GB SSD NVMe\\n\\nâ\\x82¹40.9/hr\\n\\nâ\\x82¹29,857/mo\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\nM3.250GB\\n\\n32 vCPUs\\n\\nâ\\x89¥ 2.3 GHz\\n\\n256 GB\\n\\n600 GB SSD NVMe\\n\\nâ\\x82¹81.7/hr\\n\\nâ\\x82¹59,641/mo\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\nM3.360GB\\n\\n40 vCPUs\\n\\nâ\\x89¥ 2.3 GHz\\n\\n360 GB\\n\\n900 GB SSD NVMe\\n\\nâ\\x82¹122.6/hr\\n\\nâ\\x82¹89,498/mo\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n[Read More](https://www.e2enetworks.com/product/high-memory-series)[Request a\\nFree\\nTrial](https://forms.zohopublic.com/e2enetworks/form/Requestfortrial/formperma/SdPEABJpefRANPQ0WiAms_0DaAOfgJ0omyfvxdCx7tM)\\n\\nOur sales representatives are available at\\n[+91-11-4084-4965](http://callto:+91-11-4084-4965) and\\n[sales@e2enetworks.com](mailto:sales@e2enetworks.com)  \\n\\n* Price is exclusive of 18% GST Rate\\n\\n** Monthly Prices shown are calculated using an assumed usage of 730 hr/month;\\nactual monthly costs may vary based on the number of days in a month.', start_char_idx=32121, end_char_idx=34588, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5963831606760842),\n",
       " NodeWithScore(node=TextNode(id_='f78e7ca4-33d0-4029-b5f7-4ad9dd749b4d', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='https://www.e2enetworks.com/pricing', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='09c838495f7a657ec983a961e9cf7dbd397e95c46a386923d20904bb330d32f0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='4f117db5-0a8a-4897-87db-1d3e7bc45c62', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='489cc0aed6bfbb020c72385e9b67615d311cbf15a9b49beb9c1a893015e30254'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='f383a04e-6f91-448d-967e-e195b6e474b7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='3be95528f2a53b2c974e25fc0be74761ee77aac3ca11f13e6cfadaba6e514ded')}, text='Up to nine times\\nfaster for AI training and thirty times faster for inference as compared to\\nA100, it accelerates AI training and inference, data analytics applications,\\nand HPC. The H100 GPU includes a Transformer Engine to solve trillion-\\nparameter language models. It is designed to deliver an order-of-magnitude\\nperformance leap for AI and HPC over previous generations\\nGPUs.](https://www.e2enetworks.com/product/l4)\\n\\nPlan\\n\\nvCPUs\\n\\nDedicated RAM\\n\\nDisk Space\\n\\nHourly Billing\\n\\nWeekly Billing\\n\\nMonthly Billing  \\n(Save 20%)\\n\\n **GDC3.1xH10080-60.430GB_SXM  \\n**\\n\\n60 vCPUs\\n\\n430 GB\\n\\n1600 GB SSD\\n\\nâ\\x82¹250/hr\\n\\nâ\\x82¹67,500/week\\n\\nâ\\x82¹2,50,000/mo\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n **GDC3.2xH10080-120.860GB_SXM  \\n**\\n\\n120 vCPUs\\n\\n860 GB\\n\\n3200 GB SSD\\n\\nâ\\x82¹500/hr\\n\\nâ\\x82¹1,35,000/week\\n\\nâ\\x82¹5,00,000/mo\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n[Request a Free\\nTrial](https://forms.zohopublic.com/e2enetworks/form/Requestfortrial/formperma/SdPEABJpefRANPQ0WiAms_0DaAOfgJ0omyfvxdCx7tM)\\n\\nOur sales representatives are available at\\n[+91-11-4084-4965](http://callto:+91-11-4084-4965) and\\n[sales@e2enetworks.com](mailto:sales@e2enetworks.com)  \\n\\n* Price is exclusive of 18% GST Rate\\n\\n** Monthly Prices shown are calculated using an assumed usage of 730 hr/month;\\nactual monthly costs may vary based on the number of days in a month.\\n\\n## [HGX ](https://www.e2enetworks.com/product/l4)H100\\n\\n[Use the worldâ\\x80\\x99s most powerful end-to-end AI supercomputing platform with\\nE2E Cloud.](https://www.e2enetworks.com/product/l4)\\n\\nPlan\\n\\n **vCPUs**\\n\\n **Dedicated RAM**\\n\\n **Disk Space**\\n\\n **Hourly Billing**\\n\\n **Monthly Billing**\\n\\n **Yearly Billing**\\n\\n **36 Months Billing**\\n\\n **8xH100**\\n\\n200 vCPUs\\n\\n1800 GB\\n\\n21000 GB SSD\\n\\nâ\\x82¹2800/hr\\n\\nâ\\x82¹20,00,000\\n\\nRs 342.46 per GPU/hr*\\n\\n **Rs. 5,76,00,000**\\n\\n[Reserve Now](https://myaccount.e2enetworks.com/products/create-node)\\n\\n **8xH100 Infiniband  \\n**\\n\\n200 vCPUs\\n\\n1800GB\\n\\n30000 GB SSD\\n\\nNA\\n\\nâ\\x82¹26,00,000\\n\\nRs 445.2 per GPU/hr*\\n\\n **Rs. 7,48,80,000**\\n\\n[Reserve Now](https://myaccount.e2enetworks.com/products/create-node)\\n\\n **4xH100**\\n\\n240 vCPUs\\n\\n1320 GB\\n\\n14000 GB SSD\\n\\nâ\\x82¹1000/hr\\n\\nâ\\x82¹7,30,000\\n\\nRs. 250 per GPU/hr*\\n\\n **Rs. 2,10,24,000**\\n\\n[Reserve Now](https://myaccount.e2enetworks.com/products/create-node)\\n\\n[Request a Free\\nTrial](https://forms.zohopublic.com/e2enetworks/form/Requestfortrial/formperma/SdPEABJpefRANPQ0WiAms_0DaAOfgJ0omyfvxdCx7tM)\\n\\nOur sales representatives are available at\\n[+91-11-4084-4965](http://callto:+91-11-4084-4965) and\\n[sales@e2enetworks.com](mailto:sales@e2enetworks.com)  \\n\\n* Price is exclusive of 18% GST Rate\\n\\n** Monthly Prices shown are calculated using an assumed usage of 730 hr/month;\\nactual monthly costs may vary based on the number of days in a month.\\n\\n## A100\\n\\nLeverage unprecedented acceleration and flexibility to power the worldâ\\x80\\x99s\\nhighest-performing GPU for AI, data analytics, and HPC applications.', start_char_idx=2290, end_char_idx=5197, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5950243955821561),\n",
       " NodeWithScore(node=TextNode(id_='d9348651-6286-4541-846f-d4aa2dd3bfd8', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='https://www.e2enetworks.com/pricing', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='09c838495f7a657ec983a961e9cf7dbd397e95c46a386923d20904bb330d32f0'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='46e670c3-b343-4dc5-862c-0aa6377d58ac', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='58fd6ad0fdbb9111e2cc52e3e7a5e83e500310cd9da1d01e248ec56e510bd7cc'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='a40b2bd8-841d-4adb-9d3a-1506080c16d3', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='bb97a255bdd8d0a30601ee9dcb006dcc0786ccce9182a4e1871e9ca08c5e97dc')}, text='zohopublic.com/e2enetworks/form/Requestfortrial/formperma/SdPEABJpefRANPQ0WiAms_0DaAOfgJ0omyfvxdCx7tM)\\n\\nOur sales representatives are available at\\n[+91-11-4084-4965](http://callto:+91-11-4084-4965) and\\n[sales@e2enetworks.com](mailto:sales@e2enetworks.com)  \\n\\n* Price is exclusive of 18% GST Rate\\n\\n** Monthly Prices shown are calculated using an assumed usage of 730 hr/month;\\nactual monthly costs may vary based on the number of days in a month.\\n\\n## L4\\n\\n[The NVIDIA L4 Tensor Core GPU is the breakthrough universal accelerator for\\nefficient video, AI, and graphics.](https://www.e2enetworks.com/product/l4)\\n\\nLinux L4Windows L4\\n\\nLinux L4\\n\\nPlan\\n\\nvCPUs\\n\\nDedicated RAM\\n\\n **Disk Space**\\n\\n **Hourly Billing**  \\n\\n **Weekly Billing**\\n\\nMonthly Billing\\n\\n3 months Billing\\n\\n6 months Billing\\n\\nYearly  \\nBilling  \\n\\nL4  \\n\\n25 vCPUs\\n\\n110 GB\\n\\n250 GB SSD\\n\\nâ\\x82¹50/hr\\n\\nNA\\n\\nâ\\x82¹31,755  \\n\\nâ\\x82¹92,407\\n\\nâ\\x82¹1,79,098\\n\\n **â\\x82¹3,42,954**\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n2xL4\\n\\n50 vCPUs\\n\\n220 GB\\n\\n250 GB SSD\\n\\nâ\\x82¹100/hr\\n\\nNA\\n\\nâ\\x82¹63,510\\n\\nâ\\x82¹1,84,814\\n\\nâ\\x82¹3,58,196\\n\\n **â\\x82¹6,85,908**\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n4xL4\\n\\n100 vCPUs\\n\\n440 GB\\n\\n250 GB SSD\\n\\nâ\\x82¹200/hr\\n\\nNA\\n\\nâ\\x82¹1,27,020\\n\\nâ\\x82¹3,69,628\\n\\nâ\\x82¹7,16,393\\n\\n **â\\x82¹13,71,816**\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n8xL4\\n\\n200 vCPUs\\n\\n880 GB\\n\\n250 GB SSD\\n\\nâ\\x82¹400/hr\\n\\nNA\\n\\nâ\\x82¹2,54,040\\n\\nâ\\x82¹7,39,256\\n\\nâ\\x82¹14,32,786\\n\\n **â\\x82¹27,43,632**\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n[Read More](/products/nvidia-a30)[Request a Free\\nTrial](https://forms.zohopublic.com/e2enetworks/form/Requestfortrial/formperma/SdPEABJpefRANPQ0WiAms_0DaAOfgJ0omyfvxdCx7tM)\\n\\nWindows L4\\n\\nPlan\\n\\nvCPUs\\n\\nDedicated RAM\\n\\n **Disk Space**\\n\\n **Hourly Billing**  \\n\\n **Weekly Billing**\\n\\nMonthly Billing\\n\\n3 months Billing\\n\\n6 months Billing\\n\\nYearly  \\nBilling  \\n\\nL4\\n\\n16 vCPUs\\n\\n64 GB\\n\\n250 GB SSD\\n\\nâ\\x82¹58/hr\\n\\nN/A\\n\\nâ\\x82¹37,353  \\n\\nâ\\x82¹1,09,201\\n\\nâ\\x82¹2,12,686\\n\\n **â\\x82¹3,76,542**\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n2xL4\\n\\n32 vCPUs\\n\\n128 GB\\n\\n250 GB SSD\\n\\nâ\\x82¹113/hr\\n\\nN/A\\n\\nâ\\x82¹72,988\\n\\nâ\\x82¹2,13,248\\n\\nâ\\x82¹4,15,064\\n\\n **â\\x82¹7,42,776**\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n4xL4\\n\\n64 vCPUs\\n\\n256 GB\\n\\n250 GB SSD\\n\\nâ\\x82¹224/hr\\n\\nN/A\\n\\nâ\\x82¹1,44,258\\n\\nâ\\x82¹4,21,342\\n\\nâ\\x82¹8,19,821\\n\\n **â\\x82¹14,75,244**\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n8xL4\\n\\n128 vCPUs\\n\\n512 GB\\n\\n1280 GB SSD\\n\\nâ\\x82¹445/hr\\n\\nN/A\\n\\nâ\\x82¹2,86,798\\n\\nâ\\x82¹8,37,530\\n\\nâ\\x82¹16,29,334\\n\\n **â\\x82¹29,40,180**\\n\\n[Try for Free](https://myaccount.e2enetworks.com/products/create-node)\\n\\n[Request a Free\\nTrial](https://forms.zohopublic.com/e2enetworks/form/Requestfortrial/formperma/SdPEABJpefRANPQ0WiAms_0DaAOfgJ0omyfvxdCx7tM)\\n\\nOur sales representatives are available at\\n[+91-11-4084-4965](http://callto:+91-11-4084-4965) and\\n[sales@e2enetworks.com](mailto:sales@e2enetworks.com)  \\n\\n* Price is exclusive of 18% GST Rate\\n\\n** Monthly Prices shown are calculated using an assumed usage of 730 hr/month;\\nactual monthly costs may vary based on the number of days in a month.', start_char_idx=18347, end_char_idx=21420, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.5942097306251695)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
